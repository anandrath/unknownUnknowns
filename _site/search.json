[
  {
    "objectID": "learningspiral.html",
    "href": "learningspiral.html",
    "title": "The Learning Spiral",
    "section": "",
    "text": "Learning is seldom linear. The typical syllabus is seldom effective\n\nIn order to be able to assimilate a concept, 2 things need to be fulfilled\n\nwhy do we need such a concept in the first place?\nthe idea behind the concept\n\nUnless these two conditions are fulfilled together, it is quite often difficult to marinate oneself in the concept. And unless one marinates, learning seldom happens.\nMost of our syallbus has always been linear. By the time one has completed the basics, one has lost all steam to move on to the more advanced, applied parts of the subject. This is almost always the case.\n\nWelcome to the learning spiral!\n\n\n\n\nStudy a problem\nTry to understand “why” it is a problem\nLearn a probable solution\nCode the solution\nExamine the solution to know why it is sub-optimal\nLearn a better solution\nNeed some math? Take a math detour\nGet back to code\nRepeat\n\n… and this is how we spiral up our learning non-linearly"
  },
  {
    "objectID": "MLThinking.html",
    "href": "MLThinking.html",
    "title": "Thinking in Data",
    "section": "",
    "text": "Computing the unobserved from the obseravables is as much a science as it is an art\n\nAs with all of science, Machine Learning demands passion, discipline and patience. And as with all art forms, it demands indulgence. From data sampling methods to tuning a billion parameter large language model, requires the technical acumen of the mechanic who knows his machine in and out.\nTo be able to look at the world in terms of noisy, messy obseravables and then to have the pragmatic sense and the skills to apply math and statistics to model the data - not just once, but running several experimental models to estimate the relative merit of each model, is the skill that the new age of unknown unknowns demands.\nMoreover, mastery of the art of cost-benefit analysis of models vis-a-vis the engineering effort of such projects will determine potential leaders in the field going forward.\nI make a humble attempt to organize the vast field of ML into a unified view so that the students who may be interested to pursue ML as a career could slip into the mindset seamlessly."
  },
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "Anand Rath",
    "section": "",
    "text": "I have had my fair share of experience in industrial analytics (even before the name “machine learning” caught up as a trend :) in various domains spanning over a decade. From analysing data in steel manufacturing to sensor networks, I have had the happy fortune to see this field take roots in the last decade. When not engaging with analytics, I love to indulge in geopolitics, quantum computing, category thoery and long walks…"
  },
  {
    "objectID": "about.html#education",
    "href": "about.html#education",
    "title": "Anand Rath",
    "section": "Education",
    "text": "Education\nMTech. in Computer Science, IIIT | Bangalore\nBTech. in Computer Science, BPUT | Odisha"
  },
  {
    "objectID": "about.html#experience",
    "href": "about.html#experience",
    "title": "Anand Rath",
    "section": "Experience",
    "text": "Experience\nML and Analytics | Consultant | 2019 - present\nABB | Scientist | 2011- 2019\nABB | Intern Researcher | 2009 - 2011"
  },
  {
    "objectID": "about.html#publications",
    "href": "about.html#publications",
    "title": "Anand Rath",
    "section": "Publications",
    "text": "Publications\n\nDachi: A networked querying system for industrial Internet of Things applications. ETFA 2017: 1-4\nAnalyzing Dependencies in an Industrial Automation Engineering System. ISEC 2015: 60-69\nAn approach for comparison of IEC 61131-3 graphical programs. ETFA 2013: 1-8\nField weighting for automatic bug triaging systems. SMC 2012: 2845-2848"
  },
  {
    "objectID": "about.html#patents",
    "href": "about.html#patents",
    "title": "Anand Rath",
    "section": "Patents",
    "text": "Patents\n\nA method for managing subsystems of a process plant using a distributed control system | WO2016059484A1 WIPO (PCT)\nCondition monitoring of wireless networks in industrial plants | US10931551B2 United States\nA method and device for communicating process information in wireless network of industrial plant | WO2020240004A1 WIPO (PCT)"
  },
  {
    "objectID": "4-5day.html",
    "href": "4-5day.html",
    "title": "A, rather, Functional Approach to ML for all practical purposes",
    "section": "",
    "text": "Why ML at all?\n\nFrom our news feeds to product recommendations, from ticket prices to promotional offers, from our internet browsing patterns to online/offline purchase behaviour, we are being watched. By an AI, 24/7. Welcome to the 4th Industrial Revolution. We may like it or not, we have to, as a country, engage with this revolution if we have to create meaningful value for us as a society. But, if we do not engage on our terms, it is very likely that we may become puppets by AI-enabled countries/enterprises that may fully dictate our behaviour and finally be consumed by it. There is always an AI watching us - on our phones, on our browsers, on our smart televisions, smart refrigerators and ubiquitous digital assistants like Alexa or Google Nest. To engage with AI on our own terms, we should not only understand the technology and science behind AI but also the economics and pragmatics of AI. Hence, my effort to make it a little easier for future professionals to make this engagement seamless. Hence, this series of courses, of which this workshop aspires to be the curtain-raiser. Welcome aboard!\n\n\n\n\nThe Problem and a Practical Solution\n\nFirst, thanks for your time. Let me use this opportunity to share some of my concerns. In my decade-long experience in machine learning in the corporate world, skill is a scarce resource. Of late, I have come to realize that skill is not proportional to knowledge acquisition. That’s a myth. Rather, skill is about\n\nthe tenacity to methodically engage with a problem\nexperimenting with solutions\nlots of experimenting and benchmarking\nobserving, learning and fine-tuning the experiments.\ncultivating discipline to experiment\n\nKnowledge is just a by-product. Experimenting is the hallmark of skill-development. Clearly, we, as a society, have not encouraged experimenting enough. Especially, in engineering studies. Hence, the sorry state of talent in this country. Deep techonlogies like AI, VLSI, Communication Technogies, Power Systems, Quantum Computing, Cryptology and so forth need experimenting at the deepest levels.\nThrough these series of courses, I try to invert the learning process going top-down. We experiment and learn.\n We code what we want to experiment and we learn. We code again what we learn and we experiment. \nWe begin with building models with high-abstraction libraries and see for ourselves how these models work. We learn the science behind it. We code a bit. We model again. And then we dig a little deeper.\nHere’s my practical idea to master a field of study:\n\nStudy a problem\nTry to understand “why” it is a problem\nLearn a probable solution\nCode the solution\nExamine the solution to know why it is sub-optimal\nLearn a better solution\nNeed some math? Take a math detour\nGet back to code\nRepeat\n\n… and this is how learning compounds!\n\n\n\n\n\nOutcome of the Session\n\nDevelop disciplined thinking about ML problem-solving\nDevelop a method to approach solution-design\nDevelop a taste and intuition for ML methods\nBe able to appreciate how simple mathematics can tackle really hard problems\nBe able to develop an approach to learn more ML on your own\nBe able to appreciate the economics of ML\nBecome aware of the negative impact of data privacy and powerful ML models\n\n\n\nCourse Structure\n\nThe course is spread across 3 to 3.5 days. Day-wise breakup will be provided at the beginning of the course.\n\nLet’s begin by builidng a classifier…in 5 mins :)\n\nAn appreciation for modern day ML tooling\n\nSo, what is learning from data?\n\nUnderstanding the notion of “learning a function”\n“Flexible” functions can learn just about anything\nThe Notion of “cost function”\nCalculus primer to minimize cost functions\n\nNeural Network Foundations\n\nAn Object Recognition example\nNeural Nets as function learners\nAdjusting Weights and Biases - Backpropagation\nCoding the learning loop\n\nData Ethics\n\nThe Power and Dangers of Data\nWhy should one be careful when it comes to dealing with data?\nPrivacy\nData Ownership\nPolicies\n\nBuilding a Neural Nets from Scratch\n\nStochastic Grtadient Descent\nThe MNIST Loss Function\n\nSigmoid\nStochastic Gradient Descent and Mini-Bacthes\n\nCreating an Optimizer\n\nRandom Forests\n\nHow do they work?\nDisucssion: Statistical Modeling: The Two Cultures by Leo Breiman\nSurprise!\n\nDiscussion: Why do tree-based methods still outperform deep learing on tabular data by Grinsztajn et al\n\n\n\n\n\n\n\nLogistics\n\n\nThe course structure is kept deliberately fluid - the content remains the same, the sequence may vary during the course based on student response and engagement-levels\nThe course is spread over 3 - 3.5 days\nAccess to high-speed stable internet will help make the course engaging\nStudents are advised to bring their laptops so that they can code along\n\n\n\n\n\nPrerequisites\n\n\nWorking knowledge of Python 3.0\nFamiliarlity with any of the notebook programming environments - Jupyter notebook or Google Colab\nSome working knowledge of matrices in linear algebra and calculus is good to have but NOT mandatory\n\n\n\n\n\nFuture\n\nThe ML Leadership Programme is structured as follows:\n\nArc 1/Functional ML: A functional bootstrap introduction to ML\nArc 2/Poetic Dabbling in ML: What follows is a deep dive into the math and science of ML\nArc 3/Pragmatic ML: Reconciling the Science and Economics of ML, aimed at aspiring deep tech specialists and ML entrepreneurs"
  },
  {
    "objectID": "longterm.html",
    "href": "longterm.html",
    "title": "Long-term Multi-semester Course",
    "section": "",
    "text": "A collaborative course to train ML pratitioners of the future\n\nThis is an effort to train the students in ML right from the basics of data to building and deploying production-grade ML systems. From the basic maths behind the concepts to engineering of large-scale ML systems - this course is a multi-semester effort to assimilate the vast array of concepts in ML, applying them to solve problems in various domains and turning these solutions into sustainable, evolvable and maintainable products.\nThis track aims to develop the ML mindset - the mindset that enables us to look at the world from a data lens."
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "The Age of Unknown Unknowns",
    "section": "",
    "text": "From known unknowns to unknown unknowns is the journey from computing to learning from data\n\n\n\nSource: https://fairing.co/blog/research/known-unknowns-matrix-ecommerce/\n\nComputing has always been about search. Searching for solutions in really large solutions spaces. Be it the Knuth-Morris-Pratt search or Naive Bayes algorithm, the computing community keeps looking for elegant and performant algorithms in large algorithm spaces to push the frontiers of the known unknowns - the world that we know that we are unware of till now. Here’s an interesting story: The Strassen’s matrix mulitplication of 1969 was known to be the fastest matrix mulitplication algorithm till date. But a neural network changed everything.\nIn 2022, a DeepMind deep neural network, AlphaTensor, discovered a way to multiply matrices faster.\nFor two 4X4 matrices a reduction from 49 steps to 47 means trillions of matrix calculations taking place in a GPU every day. This allows AI models to run faster and relatively cheaper. An AI had solved an AI problem.\nWelcome to the age of unknown unknowns - a time in our lives where we don’t know anymore what’s unknown to us - and AI is probably tackling what’s out there and beyond!"
  },
  {
    "objectID": "1dayicebreaker.html",
    "href": "1dayicebreaker.html",
    "title": "2 days Ice Breaker session on ML",
    "section": "",
    "text": "Getting to know the Machine Learning Landscape"
  },
  {
    "objectID": "HowToThinkinML.html",
    "href": "HowToThinkinML.html",
    "title": "Our Goal - How to Think in ML",
    "section": "",
    "text": "A Project-based learning experience to appreciate ML\n\n\n\n\nThis is a real piece of code we may begin with…\n\n\nYes, we begin with building a model right away. We play with lots of models. We tinker with code and tune the code. I believe the only way to learn the nuts and bolts of math and models is to tinker more and more and more.\nThe linear path to learning the art of ML isn’t as effective as it is made out to be. First maths fundamentals, followed by basic concepts of ML and then deep learning and foundation models is a flawed way to learn. No expert learns that away. Think about musicians, dancers. radio engineers, automobile designers - all of them have tinkered, faltered, discoverd the necessary concepts, went back to the libraries, came back and then tinkered some more.\nPlaying around with data is a great way to learn. I take students on a exploratory journey of data that showcases\n\nhow one can dig out hidden insights from data\nthe power of computer in sifting through data of unseen scale\n\nI am sure one will deeply appreciate the power of data and computation after such a journey."
  }
]